# -*- coding: utf-8 -*-
"""conversation_intent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ZY7R1nclkn7YVR8TT7bCXlc5HmcY_uo
"""

!pip install tensorflow

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
import warnings
warnings.filterwarnings("ignore")

tf.compat.v1.disable_v2_behavior()

# Read the shuffled CSV file into a pandas DataFrame
df = pd.read_csv('shuffled_prompts.csv')

# Assuming your CSV has columns 'Prompt' and 'Category' (replace with your actual column names)
prompts = df['Prompt'].astype(str).values
intents = df['Category'].astype(str).values

# Tokenize and pad sequences
tokenizer = Tokenizer()
tokenizer.fit_on_texts(prompts)
vocab_size = len(tokenizer.word_index) + 1

sequences = tokenizer.texts_to_sequences(prompts)
max_sequence_length = max(len(seq) for seq in sequences)
padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')

# Convert intents to one-hot encoding
label_encoder = LabelEncoder()
encoded_intents = label_encoder.fit_transform(intents)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_intents, test_size=0.2, random_state=42)

# Build a simple neural network model
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=16, input_length=max_sequence_length),
    GlobalAveragePooling1D(),
    Dense(16, activation='relu'),
    Dense(len(set(intents)), activation='softmax')  # Output layer with the number of classes
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=100
          , batch_size=1, validation_data=(X_test, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)

# Save the model to a file
model.save('text_classification_model.h5')

from tensorflow.keras.models import load_model

# Load the saved model
loaded_model = load_model('text_classification_model.h5')

# Example: Make predictions on new data
#new_data = ["I watched a great movie last night!", "Planning to grab dinner at that new place."]
new_data = [str(input("enter data:::   "))]
# Tokenize and pad the new data
new_sequences = tokenizer.texts_to_sequences(new_data)
new_padded_sequences = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')

# Make predictions
predictions = loaded_model.predict(new_padded_sequences)
# If you have used one-hot encoding for labels, you can use argmax to get the predicted class
predicted_classes = predictions.argmax(axis=1)

# Mapping dictionary
class_mapping = {0: "Dinner", 1: "Movies"}

# Convert numeric predictions to string labels
predicted_class_strings = [class_mapping[label] for label in predicted_classes]

# Print the predictions with string labels
for text, predicted_class_string in zip(new_data, predicted_class_strings):
    print(f"Text: {text}\nPredicted Class: {predicted_class_string}\n")

